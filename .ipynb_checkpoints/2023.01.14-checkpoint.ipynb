{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afe2e755",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시흥시 정왕동\n",
      "\n",
      "현재 온도4.1°\n",
      "\n",
      "흐림\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(weatherStatus)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 공기 상태\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m air \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweather_quick_inner list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mul\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(air)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#infos = air.find_all('li', {'class' : 'item_today'})\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#or info in infos:\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#   print(info.text)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\nam\\lib\\site-packages\\bs4\\element.py:2173\u001b[0m, in \u001b[0;36mResultSet.__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   2172\u001b[0m     \u001b[38;5;124;03m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   2174\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultSet object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. You\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m key\n\u001b[0;32m   2175\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "html = requests.get('https://weather.naver.com/today/02390132')\n",
    "soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "# 위치\n",
    "address = soup.find('div', {'class': 'location_area' }).find('strong', {'class' : 'location_name'}).text\n",
    "print(address)\n",
    "\n",
    "# 날씨 정보\n",
    "weather_data = soup.find('div', {'class' : 'weather_area'})\n",
    "\n",
    "# 현재 온도\n",
    "temperature = weather_data.find('strong', {'class' : 'current'}).text #.strip() 공백제거 (strip()[5:] - 슬라이싱 앞에 현재 온도 제거)\n",
    "print(temperature)\n",
    "\n",
    "# 날씨 상태\n",
    "weatherStatus = weather_data.find('span', {'class' : 'weather'}).text\n",
    "print(weatherStatus)\n",
    "\n",
    "# 공기 상태\n",
    "#air = soup.find_all('div', {'class' : 'weather_quick_inner list'}).find('ul', {''})\n",
    "#print(air)\n",
    "#infos = air.find_all('li', {'class' : 'item_today'})\n",
    "\n",
    "#or info in infos:\n",
    "#   print(info.text)\n",
    "    \n",
    "a = soup.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "023c34d7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1-py3-none-any.whl\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.11.1 bs4-0.0.1 soupsieve-2.3.2.post1\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "#from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "url=\"https://weather.naver.com/today/02390132\"\n",
    "browser.get(url)\n",
    "boxes = browser.find_elements(By.CSS_SELECTOR,\".nation_map a.zone.z=\") #  elements = 리스트를 뽑아줌\n",
    "\n",
    "#import time\n",
    "#time.sleep(3)\n",
    "for box in boxes:\n",
    "    # title = browser.find~~~~`\n",
    "    title = box.find_element(By.CSS_SELECTOR,\"strong.title\") #기사타이틀 \n",
    "    newspaper = box.find_element(By.CSS_SELECTOR,\".information span\").text #신문사\n",
    "    sport = box.find_element(By.CSS_SELECTOR,\".information span:nth-child(2)\").text #스포츠 상위 주제\n",
    "    print(sport, newspaper, title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23268470",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\anaconda3\\envs\\project2023\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawling2023",
   "language": "python",
   "name": "nam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
